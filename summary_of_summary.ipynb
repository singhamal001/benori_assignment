{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0...\n",
      "Row 0 summarized successfully.\n",
      "Processing row 1...\n",
      "Row 1 summarized successfully.\n",
      "Processing row 2...\n",
      "Row 2 summarized successfully.\n",
      "Processing row 3...\n",
      "Row 3 summarized successfully.\n",
      "Processing row 4...\n",
      "Row 4 summarized successfully.\n",
      "Processing row 5...\n",
      "Row 5 summarized successfully.\n",
      "Processing row 6...\n",
      "Rate limit reached: Rate limit reached for gpt-4 in organization org-HlU6bIJXfgm1qTAnb5XjWFGy on tokens per min (TPM): Limit 10000, Used 7361, Requested 4494. Please try again in 11.13s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Waiting for 60 seconds before retrying...\n",
      "Row 6 summarized successfully.\n",
      "Processing row 7...\n",
      "Row 7 summarized successfully.\n",
      "Processing row 8...\n",
      "Row 8 summarized successfully.\n",
      "Processing row 9...\n",
      "Row 9 summarized successfully.\n",
      "Processing row 10...\n",
      "Rate limit reached: Rate limit reached for gpt-4 in organization org-HlU6bIJXfgm1qTAnb5XjWFGy on tokens per min (TPM): Limit 10000, Used 4133, Requested 8065. Please try again in 13.188s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Waiting for 60 seconds before retrying...\n",
      "Row 10 summarized successfully.\n",
      "Processing row 11...\n",
      "Row 11 summarized successfully.\n",
      "Processing row 12...\n",
      "Row 12 summarized successfully.\n",
      "Processing row 13...\n",
      "Input too large. Truncated the text by removing the last 100 words and retrying...\n",
      "Row 13 summarized successfully.\n",
      "Processing row 14...\n",
      "Row 14 summarized successfully.\n",
      "Processing row 15...\n",
      "Row 15 summarized successfully.\n",
      "Processing row 16...\n",
      "Row 16 summarized successfully.\n",
      "All summaries processed and saved to summarized_summaries.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def summarize_text(text, max_words=1000, max_retries=5):\n",
    "    \"\"\"\n",
    "    Uses OpenAI's Chat API to summarize a text to a maximum of max_words words.\n",
    "    On rate limit errors, waits 60 seconds before retrying.\n",
    "    On input size errors, truncates the last 100 words and retries.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    current_text = text\n",
    "    while retries < max_retries:\n",
    "        prompt = (\n",
    "            f\"Please summarize the following text so that the final summary is no longer than {max_words} words. \"\n",
    "            \"Include all key details in a concise manner.\\n\\n\"\n",
    "            f\"Text:\\n{current_text}\\n\\n\"\n",
    "            \"Summary:\"\n",
    "        )\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.5,\n",
    "            )\n",
    "            return response.choices[0].message[\"content\"].strip()\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            if \"Rate limit reached\" in error_str:\n",
    "                # Wait for 60 seconds and then retry\n",
    "                print(f\"Rate limit reached: {error_str}\")\n",
    "                print(\"Waiting for 60 seconds before retrying...\")\n",
    "                time.sleep(60)\n",
    "                retries += 1\n",
    "                continue\n",
    "            elif \"Request too large\" in error_str or \"input or output tokens must be reduced\" in error_str:\n",
    "                # Truncate the last 100 words from current_text and try again\n",
    "                words = current_text.split()\n",
    "                if len(words) > 100:\n",
    "                    current_text = \" \".join(words[:-100])\n",
    "                    print(\"Input too large. Truncated the text by removing the last 100 words and retrying...\")\n",
    "                    retries += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(\"Text too short to truncate further. \" + error_str)\n",
    "            else:\n",
    "                # For other errors, raise the exception\n",
    "                raise e\n",
    "    raise Exception(\"Max retries exceeded.\")\n",
    "\n",
    "def main():\n",
    "    # Load the Parquet file containing the summaries\n",
    "    df = pd.read_parquet(\"final_categorized_with_themes_and_summaries.parquet\")\n",
    "    \n",
    "    # Ensure that there is a \"summary\" column in your dataframe\n",
    "    if \"summary\" not in df.columns:\n",
    "        print(\"No 'summary' column found in the dataframe.\")\n",
    "        return\n",
    "\n",
    "    condensed_summaries = []\n",
    "    \n",
    "    # Iterate over each row and summarize the summary\n",
    "    for idx, row in df.iterrows():\n",
    "        original_summary = row[\"summary\"]\n",
    "        print(f\"Processing row {idx}...\")\n",
    "        try:\n",
    "            condensed = summarize_text(original_summary, max_words=1000)\n",
    "            condensed_summaries.append(condensed)\n",
    "            print(f\"Row {idx} summarized successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing row {idx}: {e}\")\n",
    "            condensed_summaries.append(\"Error in summarization.\")\n",
    "        # Pause briefly (if not rate-limited already)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Add the condensed summaries to the dataframe\n",
    "    df[\"condensed_summary\"] = condensed_summaries\n",
    "    \n",
    "    # Save the new dataframe to a CSV file\n",
    "    df.to_csv(\"summarized_summaries.csv\", index=False)\n",
    "    print(\"All summaries processed and saved to summarized_summaries.csv\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"summarized_summaries.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"summarized_summaries.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PwC India's Financial Services (FS) Risk Symposium: Ministry of Finance keynote session - February 2025\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[12,\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1450"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[12,\"condensed_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
