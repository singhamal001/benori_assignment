{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This document describes a two-part Python script that uses Selenium to scrape and extract information from the KPMG insights page.\n",
    "\n",
    "### Part 1\n",
    "- Collects hyperlinks from the KPMG insights page and saves them to `links.csv`.\n",
    "\n",
    "### Part 2\n",
    "- Reads the collected links from `insight-links-kpmg.csv`.\n",
    "- Visits each link to extract additional details like title, description, date, content, and PDF links.\n",
    "- Filters results based on the publication date (within the last 30 days).\n",
    "- Saves the extracted details to `insights-details-kpmg.csv`.\n",
    "This document describes a Python script that uses Selenium to scrape links from the KPMG insights page and saves them to a CSV file.\n",
    "\n",
    "The script performs the following tasks:\n",
    "1. Launches a Chrome browser using WebDriver.\n",
    "2. Accepts cookies if prompted.\n",
    "3. Scrolls through the page to load content.\n",
    "4. Extracts links from the page.\n",
    "5. Handles pagination to gather at least 100 links.\n",
    "6. Saves the collected links to a CSV file.\n",
    "\n",
    "## Dependencies\n",
    "- Python\n",
    "- selenium\n",
    "- webdriver_manager\n",
    "- csv\n",
    "\n",
    "## Code Explanation\n",
    "\n",
    "### Function Descriptions\n",
    "\n",
    "1. **accept_cookies()**\n",
    "   - Handles the acceptance of cookies if a cookie consent button is present on the webpage.\n",
    "   - Uses XPath to locate the button and attempts to click it.\n",
    "   - If the button is not found, the function exits silently.\n",
    "\n",
    "2. **extract_links()**\n",
    "   - Extracts hyperlinks from specific tiles on the page.\n",
    "   - Uses CSS selectors to locate the anchor tags within tile elements.\n",
    "   - Appends each valid link to the `links` list.\n",
    "\n",
    "3. **extract_details(url)**\n",
    "   - Navigates to a given URL and extracts title, description, date, main content, and PDF links if available.\n",
    "   - Handles exceptions if elements are missing.\n",
    "   - Returns a dictionary with the extracted information.\n",
    "\n",
    "4. **Main Script Logic**\n",
    "   - Initializes the WebDriver and opens the webpage.\n",
    "   - Manages scrolling and pagination to collect links.\n",
    "   - Reads links from `insight-links-kpmg.csv`.\n",
    "   - Extracts details from each link if they were published in the last 30 days.\n",
    "   - Saves the extracted data to `insights-details-kpmg.csv`.\n",
    "   - Closes the WebDriver.\n",
    "\n",
    "1. **accept_cookies()**\n",
    "   - Handles the acceptance of cookies if a cookie consent button is present on the webpage.\n",
    "   - Uses XPath to locate the button and attempts to click it.\n",
    "   - If the button is not found, the function exits silently.\n",
    "\n",
    "2. **extract_links()**\n",
    "   - Extracts hyperlinks from specific tiles on the page.\n",
    "   - Uses CSS selectors to locate the anchor tags within tile elements.\n",
    "   - Appends each valid link to the `links` list.\n",
    "\n",
    "3. **Main Script Logic**\n",
    "   - Initializes the WebDriver and opens the webpage.\n",
    "   - Manages scrolling and pagination to ensure all content is loaded and at least 100 links are collected.\n",
    "   - Handles exceptions during pagination to avoid script crashes.\n",
    "   - Saves the collected links to a CSV file and closes the browser.\n",
    "\n",
    "\n",
    "### Brief Explanation\n",
    "This script is designed to automate the process of extracting and enriching information from the KPMG insights page using Selenium.\n",
    "\n",
    "- **Part 1:** Collects links from the main insights page and saves them to a CSV file.\n",
    "- **Part 2:** Reads these links, navigates to each, extracts detailed information (title, description, date, content, and PDF links), filters based on the publication date (last 30 days), and saves the results to a new CSV file.\n",
    "This script is designed to automate the process of extracting hyperlinks from the KPMG insights page using Selenium. It begins by opening the website in a Chrome browser, handles cookie acceptance if required, and scrolls through the page to load all available content. The script identifies and collects links from specific elements on the page, handles pagination to ensure a minimum of 100 links are collected, and finally, saves the extracted information from these links to a CSV file named `insights-details-kpmg.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 104 links and saved to links.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "driver.get(\"https://kpmg.com/in/en/insights.html\")\n",
    "\n",
    "def accept_cookies():\n",
    "    try:\n",
    "        accept_button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Accept') or contains(text(), 'Agree')]\")\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "accept_cookies()\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(2)\n",
    "\n",
    "links = []\n",
    "\n",
    "def extract_links():\n",
    "    tiles = driver.find_elements(By.CSS_SELECTOR, \"div.cmp-filterlist__tile a.cmp-filterlist__tile--action-link\")\n",
    "    for tile in tiles:\n",
    "        link = tile.get_attribute(\"href\")\n",
    "        if link:\n",
    "            links.append(link)\n",
    "\n",
    "extract_links()\n",
    "\n",
    "while len(links) < 100:\n",
    "    try:\n",
    "        pagination = driver.find_element(By.CSS_SELECTOR, \"div.cmp-filterlist__pagination[role='navigation']\")\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", pagination)\n",
    "        time.sleep(1)\n",
    "\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, \"button.cmp-filterlist__pagination--next[aria-label='Next set of results']\")\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        extract_links()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "with open(\"insight-links-kpmg.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Link\"])\n",
    "    for link in links:\n",
    "        writer.writerow([link])\n",
    "\n",
    "print(f\"Collected {len(links)} links and saved to links.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted details from 7 links and saved to insights_details.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "def accept_cookies():\n",
    "    try:\n",
    "        accept_button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Accept') or contains(text(), 'Agree')]\")\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def extract_details(url):\n",
    "    driver.get(url)\n",
    "    accept_cookies()\n",
    "    time.sleep(2)\n",
    "\n",
    "    breadcrumbs = driver.find_elements(By.CSS_SELECTOR, \"ol.cmp-breadcrumb__list li.cmp-breadcrumb__item\")\n",
    "    if len(breadcrumbs) < 3 or \"Insights\" not in breadcrumbs[1].text:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        title = driver.find_element(By.CSS_SELECTOR, \"h1.cmp-hero-csi__title\").text\n",
    "    except:\n",
    "        title = \"\"\n",
    "\n",
    "    try:\n",
    "        description = driver.find_element(By.CSS_SELECTOR, \"div.cmp-hero-csi__description\").text\n",
    "    except:\n",
    "        description = \"\"\n",
    "\n",
    "    try:\n",
    "        date = driver.find_element(By.CSS_SELECTOR, \"div.cmp-hero-csi__article-date span#heroCsiMonth\").text\n",
    "        date_object = datetime.strptime(date, \"%d %b, %Y\")\n",
    "    except:\n",
    "        date_object = None\n",
    "\n",
    "    try:\n",
    "        content_sections = driver.find_elements(By.CSS_SELECTOR, \"div.section.container.responsivegrid div.cmp-text p, div.section.container.responsivegrid div.cmp-text h3\")\n",
    "        content = \"\\n\".join([section.text for section in content_sections])\n",
    "    except:\n",
    "        content = \"\"\n",
    "\n",
    "    try:\n",
    "        pdf_links = driver.find_elements(By.XPATH, \"//a[contains(@href, '.pdf')]\")\n",
    "        pdf_link = pdf_links[0].get_attribute(\"href\") if pdf_links else \"\"\n",
    "    except:\n",
    "        pdf_link = \"\"\n",
    "\n",
    "    return {\n",
    "        \"url_link\": url,\n",
    "        \"Title\": title,\n",
    "        \"Description\": description,\n",
    "        \"Date\": date_object,\n",
    "        \"Content\": content,\n",
    "        \"Pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "links = []\n",
    "with open(\"insight-links-kpmg.csv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        links.append(row[0])\n",
    "\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "details = []\n",
    "for link in links:\n",
    "    detail = extract_details(link)\n",
    "    if detail and isinstance(detail[\"Date\"], datetime):\n",
    "        if detail[\"Date\"] < start_date:\n",
    "            break\n",
    "        if start_date <= detail[\"Date\"] <= end_date:\n",
    "            details.append(detail)\n",
    "\n",
    "with open(\"insights-details-kpmg.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\"url_link\", \"Title\", \"Description\", \"Date\", \"Content\", \"Pdf_link\"])\n",
    "    writer.writeheader()\n",
    "    for detail in details:\n",
    "        writer.writerow(detail)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(f\"Extracted details from {len(details)} links and saved to insights-details-kpmg.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
